{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import datetime\n",
    "import os\n",
    "os.environ['PROJ_LIB'] = '/data/keeling/a/sshu3/anaconda2/share/proj'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cbook as cbook\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "from netCDF4 import Dataset as NetCDFFile\n",
    "from scipy.interpolate import interp1d\n",
    "import auxiliary_lib as au\n",
    "import isamcalc_lib as isam\n",
    "import subprocess\n",
    "import socplot_lib as socplt\n",
    "import Fluxtools as flux\n",
    "import copy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:36: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:38: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:48: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:49: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:50: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:51: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:52: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:53: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:54: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desfn\n",
      "730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:75: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "Fluxtools.py:61: RuntimeWarning: Mean of empty slice\n",
      "  daily_srs[i] = np.nanmean(srs[i*nstep:(i+1)*nstep])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlhor\n",
      "1095\n",
      "ustwt\n",
      "1825\n",
      "uswpt\n",
      "1095\n",
      "uscrt\n",
      "1095\n",
      "usmyb\n",
      "1460\n",
      "ustw1\n",
      "1095\n",
      "usstj\n",
      "365\n"
     ]
    }
   ],
   "source": [
    "nosites = 8\n",
    "site = [\"desfn\", \"nlhor\", \"ustwt\", \"uswpt\", \"uscrt\", \"usmyb\", \"ustw1\", \"usstj\"]\n",
    "obstag = [\"DESfN\", \"NLHor\", \"USTwt\", \"USWPT\", \"USCRT\", \"USMyb\", \"USTw1\", \"USStJ\"]\n",
    "wttag = [\"DE-SfN_WT.nc\", \"NL-Hor_WT.nc\", \"US-Twt_WT.nc\", \"US-WPT_WT.nc\", \"US-CRT_WT.nc\", \"US-Myb_WT.nc\", \"US-Tw1_WT.nc\", \"US-StJ_WT.nc\"]\n",
    "wtpath = \"/data/jain1/c/sshu3/SBGC/data/CONUS_CH4/\"\n",
    "styear = [2012, 2004, 2010, 2011, 2011, 2012, 2013, 2018]\n",
    "years = [2, 3, 5, 3, 3, 4, 3, 1]\n",
    "window = 20\n",
    "\n",
    "ch4_obs_20d_avg = []\n",
    "ch4_mod_20d_avg = []\n",
    "wt_obs_20d_avg = []\n",
    "ch4_prod_20d_avg = []\n",
    "ch4_oxid_20d_avg = []\n",
    "ch4_ebul_20d_avg = []\n",
    "ch4_aere_20d_avg = []\n",
    "ch4_20d_avg = []\n",
    "o2_20d_avg = []\n",
    "\n",
    "ch4_obs_20d_std = []\n",
    "ch4_mod_20d_std = []\n",
    "wt_obs_20d_std = []\n",
    "ch4_prod_20d_std = []\n",
    "ch4_oxid_20d_std = []\n",
    "ch4_ebul_20d_std = []\n",
    "ch4_aere_20d_std = []\n",
    "ch4_20d_std = []\n",
    "o2_20d_std = []\n",
    "\n",
    "ch4_err = []\n",
    "\n",
    "# Check CH4 aq and ga in the whole column\n",
    "fname_gas_ch4=\"ch4_mass_gas.txt\"\n",
    "fname_liq_ch4=\"ch4_mass_liq.txt\"\n",
    "temp = pd.read_csv(fname_gas_ch4, delim_whitespace=True, header=None)\n",
    "ch4_gas = temp[:].as_matrix()\n",
    "temp = pd.read_csv(fname_liq_ch4, delim_whitespace=True, header=None)\n",
    "ch4_liq = temp[:].as_matrix()\n",
    "\n",
    "# Open text file (model simulation)\n",
    "# Combine the results from all sites into 1 dataframe\n",
    "# [DE-SfN, NL-Nor, US-Twt, US-WPT, US-CRT, US-Myb, US-Tw1, US-StJ]\n",
    "for i in np.arange(0,nosites):\n",
    "    # Get the model estimation\n",
    "    fname=site[i]+\"_daily_10_tgas.txt\"\n",
    "    ch4 = pd.read_csv(fname, delim_whitespace=True, header=None)\n",
    "    # First column is the net CH4 flux\n",
    "    ch4_emis = ch4.iloc[:,0].as_matrix()\n",
    "    ch4_prod = ch4.iloc[:,1].as_matrix()\n",
    "    ch4_oxid = ch4.iloc[:,2].as_matrix()\n",
    "    ch4_ebul = ch4.iloc[:,3].as_matrix()\n",
    "    ch4_aere = ch4.iloc[:,4].as_matrix()\n",
    "    ch4_conc = ch4.iloc[:,5].as_matrix()   # ch4_conc is actually ch4_diff\n",
    "    o2_conc  = ch4.iloc[:,6].as_matrix()    \n",
    "    totlen = len(ch4_emis)\n",
    "    print(site[i])\n",
    "    print(totlen)\n",
    "    days = 365*years[i]\n",
    "    ch4_mod_daily = ch4_emis[totlen-days:totlen]\n",
    "    ch4_prod_daily = ch4_prod[totlen-days:totlen]\n",
    "    ch4_oxid_daily = ch4_oxid[totlen-days:totlen]\n",
    "    ch4_ebul_daily = ch4_ebul[totlen-days:totlen]\n",
    "    ch4_aere_daily = ch4_aere[totlen-days:totlen]\n",
    "    #ch4_conc_daily = ch4_conc[totlen-days:totlen]\n",
    "    ch4_conc_daily = ch4_emis[totlen-days:totlen]-ch4_ebul[totlen-days:totlen]-ch4_aere[totlen-days:totlen]\n",
    "    o2_conc_daily  = o2_conc[totlen-days:totlen]\n",
    "    ch4_err.append((ch4_mod_daily-ch4_conc_daily-ch4_ebul_daily-ch4_aere_daily))\n",
    "    \n",
    "    # Open the observations\n",
    "    # First CH4 flux\n",
    "    fname=\"site_methane.csv\"\n",
    "    ch4_obs = pd.read_csv(fname)\n",
    "    site_year = np.arange(styear[i], styear[i]+years[i])\n",
    "    temp_obs = ch4_obs[obstag[i]]\n",
    "    ch4_obs_raw = temp_obs[ch4_obs.YEAR.astype(\"int\").isin(site_year)].as_matrix()\n",
    "    ch4_obs_raw[ch4_obs_raw < -500] = float(\"nan\")\n",
    "    ch4_obs_raw = ch4_obs_raw * 3600\n",
    "    # Want to remove Feb 29th for leap year\n",
    "    temp_obs = ch4_obs[\"DOY\"]\n",
    "    ch4_doy = temp_obs[ch4_obs.YEAR.astype(\"int\").isin(site_year)].as_matrix()\n",
    "    ch4_obs_raw = np.delete(ch4_obs_raw, np.where(ch4_doy==366),0)\n",
    "    # Aggregate from half hourly to daily\n",
    "    ch4_obs_daily = flux.hr2daily(ch4_obs_raw, \"agg\", 48)\n",
    "    # Transform unit from umol/day to gCH4/day\n",
    "    ch4_obs_daily = 16. * ch4_obs_daily / 1e6\n",
    "    \n",
    "    # 20-days moving window average\n",
    "    #ch4_obs_20d_avg.append(pd.rolling_mean(ch4_obs_daily, window))\n",
    "    ch4_obs_daily=pd.DataFrame(data=ch4_obs_daily)\n",
    "    ch4_obs_20d_avg.append(ch4_obs_daily.rolling(window).mean())\n",
    "    ch4_mod_daily=pd.DataFrame(data=ch4_mod_daily)\n",
    "    ch4_mod_20d_avg.append(ch4_mod_daily.rolling(window).mean())\n",
    "    ch4_prod_daily=pd.DataFrame(data=ch4_prod_daily)\n",
    "    ch4_prod_20d_avg.append(ch4_prod_daily.rolling(window).mean())\n",
    "    ch4_oxid_daily=pd.DataFrame(data=ch4_oxid_daily)\n",
    "    ch4_oxid_20d_avg.append(ch4_oxid_daily.rolling(window).mean())\n",
    "    ch4_ebul_daily=pd.DataFrame(data=ch4_ebul_daily)\n",
    "    ch4_ebul_20d_avg.append(ch4_ebul_daily.rolling(window).mean())\n",
    "    ch4_aere_daily=pd.DataFrame(data=ch4_aere_daily)\n",
    "    ch4_aere_20d_avg.append(ch4_aere_daily.rolling(window).mean())\n",
    "    ch4_conc_daily=pd.DataFrame(data=ch4_conc_daily)\n",
    "    ch4_20d_avg.append(ch4_conc_daily.rolling(window).mean())\n",
    "    o2_conc_daily=pd.DataFrame(data=o2_conc_daily)\n",
    "    o2_20d_avg.append(o2_conc_daily.rolling(window).mean())\n",
    "    \n",
    "    # Calculate the STD within the 20-days window\n",
    "    ch4_obs_20d_std.append(ch4_obs_daily.rolling(window).std())\n",
    "    ch4_mod_20d_std.append(ch4_mod_daily.rolling(window).std())\n",
    "    ch4_prod_20d_std.append(ch4_prod_daily.rolling(window).std())\n",
    "    ch4_oxid_20d_std.append(ch4_oxid_daily.rolling(window).std())\n",
    "    ch4_ebul_20d_std.append(ch4_ebul_daily.rolling(window).std())\n",
    "    ch4_aere_20d_std.append(ch4_aere_daily.rolling(window).std())      \n",
    "    ch4_20d_std.append(ch4_conc_daily.rolling(window).std())\n",
    "    o2_20d_std.append(o2_conc_daily.rolling(window).std())\n",
    "    \n",
    "    # Second water table depth, m\n",
    "    fname=wtpath+wttag[i]\n",
    "    nclu=NetCDFFile(fname,'r')\n",
    "    wt_obs = nclu.variables['WT'][:]\n",
    "    wt1d_obs = wt_obs[:,0,0]\n",
    "    wt_obs_daily_full = flux.hr2daily(wt1d_obs, \"avg\", 48)\n",
    "    # We need to tailor the length to that of the CH4 obs.\n",
    "    wt_obs_daily = wt_obs_daily_full[0:len(ch4_obs_daily)]\n",
    "    # 20-days moving window average\n",
    "    wt_obs_daily=pd.DataFrame(data=wt_obs_daily)\n",
    "    wt_obs_20d_avg.append(wt_obs_daily.rolling(window).mean())\n",
    "    wt_obs_20d_std.append(wt_obs_daily.rolling(window).std())\n",
    "    # We need the actual water table for Mayberry Wetland site since it is always above zero.\n",
    "    # The water table being read by ISAM is modulated once the water table exceeds zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Special case: read into US-StJ_old\n",
    "    # Get the model estimation\n",
    "    fname=\"usstj_old_daily_10_tgas.txt\"\n",
    "    ch4 = pd.read_csv(fname, delim_whitespace=True, header=None)\n",
    "    # First column is the net CH4 flux\n",
    "    ch4_emis = ch4.iloc[:,0].as_matrix()\n",
    "    ch4_prod = ch4.iloc[:,1].as_matrix()\n",
    "    ch4_oxid = ch4.iloc[:,2].as_matrix()\n",
    "    ch4_ebul = ch4.iloc[:,3].as_matrix()\n",
    "    ch4_aere = ch4.iloc[:,4].as_matrix()\n",
    "    ch4_conc = ch4.iloc[:,5].as_matrix()   # ch4_conc is actually ch4_diff\n",
    "    o2_conc  = ch4.iloc[:,6].as_matrix()    \n",
    "    totlen = len(ch4_emis)\n",
    "    print(totlen)\n",
    "    days = 365\n",
    "    usstj_mod_daily = ch4_emis[totlen-days:totlen]\n",
    "    \n",
    "    # 20-days moving window average\n",
    "    #ch4_obs_20d_avg.append(pd.rolling_mean(ch4_obs_daily, window))\n",
    "    usstj_mod_daily=pd.DataFrame(data=usstj_mod_daily)\n",
    "    usstj_mod_20d_avg = usstj_mod_daily.rolling(window).mean()\n",
    "    \n",
    "    # Calculate the STD within the 20-days window\n",
    "    usstj_mod_20d_std = usstj_mod_daily.rolling(window).std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================\n",
    "# Calculate the refined Willmott's index\n",
    "#========================================================\n",
    "for i in np.arange(0,nosites):\n",
    "    #Xobs = ch4_obs_20d_avg[i]   # Obs CH4 flux\n",
    "    #Xmod = ch4_mod_20d_avg[i]   # CH4 flux from ISAM\n",
    "    Xobs = ch4_obs_daily  # Obs CH4 flux\n",
    "    Xmod = ch4_mod_daily   # CH4 flux from ISAM\n",
    "    #if(i == 4):\n",
    "    #    Xobs[Xobs>0.01] = np.float('nan')\n",
    "    #    Xmod[0:200] = np.float('nan')\n",
    "    #    Xobs[280:len(Xobs)] = np.float('nan')\n",
    "    #    Xmod[280:len(Xmod)] = np.float('nan')\n",
    "    #    Xmod = Xmod*0.8\n",
    "    #if(i == 7):\n",
    "    #    #Xobs[0:200] = np.float('nan')\n",
    "    #    #Xmod[0:200] = np.float('nan')\n",
    "    #    Xobs[280:len(Xobs)] = np.float('nan')\n",
    "    #    Xmod[280:len(Xmod)] = np.float('nan')\n",
    "    #    Xmod = Xmod*0.8\n",
    "    absdiff_obs = np.nansum(np.abs(Xobs - np.nanmean(Xobs)))\n",
    "    absdiff_mod = np.nansum(np.abs(Xmod - Xobs))\n",
    "    if(absdiff_mod <= 2*absdiff_obs):\n",
    "        wmidx = 1 - absdiff_mod/(2*absdiff_obs)\n",
    "        #print('tag1')\n",
    "    else: \n",
    "        wmidx = 2*absdiff_obs/absdiff_mod - 1\n",
    "        #print('tag2')\n",
    "    print(wmidx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = cp.deepcopy(ch4_obs_daily)\n",
    "#pp[pp>0.01] = np.float('nan')\n",
    "plt.plot(ch4_obs_daily)\n",
    "plt.plot(ch4_mod_daily)\n",
    "#plt.plot(ch4_mod_20d_avg[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(~np.isnan(ch4_obs_daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch4_obs_daily=pd.DataFrame(data=ch4_obs_daily)\n",
    "dd = ch4_obs_daily.rolling(20).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(~np.isnan(dd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================\n",
    "# Calculate R2 for specific site, no moving window average\n",
    "#==============================================================\n",
    "for i in np.arange(4,5):\n",
    "    Xobs = ch4_obs_daily.as_matrix()[:,0]   # Obs CH4 flux\n",
    "    Xmod = ch4_mod_daily.as_matrix()[:,0]   # CH4 flux from ISAM\n",
    "    Xobs[np.isnan(Xmod)] = np.float('nan')\n",
    "    Xmod[np.isnan(Xobs)] = np.float('nan')\n",
    "    correlation = ma.corrcoef(ma.masked_invalid(Xobs), ma.masked_invalid(Xmod))[0,1]\n",
    "    r2 = correlation*correlation\n",
    "    print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2980996347915514\n",
      "--\n",
      "0.10912661123045671\n",
      "0.9284237220817005\n",
      "0.04601781759564427\n",
      "0.638098146290391\n",
      "0.27812592636203204\n",
      "0.12439075431913356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n",
      "/data/keeling/a/sshu3/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#========================================================\n",
    "# Calculate R2\n",
    "#========================================================\n",
    "for i in np.arange(0,nosites):\n",
    "    Xobs = ch4_obs_20d_avg[i].loc[:,0].as_matrix()   # Obs CH4 flux\n",
    "    Xmod = ch4_mod_20d_avg[i].loc[:,0].as_matrix()   # CH4 flux from ISAM\n",
    "    Xobs[np.isnan(Xmod)] = np.float('nan')\n",
    "    Xmod[np.isnan(Xobs)] = np.float('nan')\n",
    "    correlation = ma.corrcoef(ma.masked_invalid(Xobs), ma.masked_invalid(Xmod))[0,1]\n",
    "    r2 = correlation*correlation\n",
    "    print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================\n",
    "# Scatter plot to check the model performance\n",
    "#========================================================\n",
    "#Xobs = ch4_obs_20d_avg[4]   # Obs CH4 flux\n",
    "#Xmod = ch4_mod_20d_avg[4]   # CH4 flux from ISAM\n",
    "plt.scatter(Xobs, Xmod)\n",
    "#plt.ylim((-0.005, 0.005))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================\n",
    "# Calculate ME for specific site\n",
    "#========================================================\n",
    "for i in np.arange(0,nosites):\n",
    "    Xobs = ch4_obs_daily.as_matrix()[:,0]   # Obs CH4 flux\n",
    "    Xmod = ch4_mod_daily.as_matrix()[:,0]   # CH4 flux from ISAM\n",
    "    me = np.nanmean(Xobs-Xmod)\n",
    "    print(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================\n",
    "# Calculate ME\n",
    "#========================================================\n",
    "for i in np.arange(0,nosites):\n",
    "    Xobs = ch4_obs_20d_avg[i]   # Obs CH4 flux\n",
    "    Xmod = ch4_mod_20d_avg[i]   # CH4 flux from ISAM\n",
    "    me = np.nanmean(Xobs-Xmod)\n",
    "    print(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('aaa.txt', ch4_obs_20d_std[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(ch4_obs_20d_avg[7]- ch4_obs_20d_std[7])\n",
    "plt.plot(ch4_obs_daily)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot results for each site separately\n",
    "# Put site specific settings here\n",
    "ylims_ch4 = [0.5, 0.5, 0.6, 1.2, 0.05, 1.0, 1.0, 0.5]\n",
    "ylims_wt = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "#start_t = [\"2012-01-10\", \"2004-01-10\", \"2010-01-10\", \"2011-01-10\", \"2011-01-10\", \"2011-01-10\", \"2013-01-10\"]\n",
    "start_t = [\"2012\", \"2004\", \"2010\", \"2011\", \"2011\", \"2011\", \"2013\", \"2018\"]\n",
    "\n",
    "for i in np.arange(nosites-2,nosites-1):\n",
    "    std_lower = np.squeeze(ch4_obs_20d_avg[i] - ch4_obs_20d_std[i])\n",
    "    std_upper = np.squeeze(ch4_obs_20d_avg[i] + ch4_obs_20d_std[i])\n",
    "    std_lower[std_lower<0] = 0.\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(16,10))\n",
    "    ax1 = fig.axes[0]\n",
    "    plt.ylim((-0.05, ylims_ch4[i]))\n",
    "    xtime = pd.date_range(start=start_t[i], periods=len(ch4_obs_20d_avg[i]), freq='D')\n",
    "    xtime2 = pd.date_range(start=start_t[i], periods=len(ch4_mod_20d_avg[i]), freq='D')\n",
    "\n",
    "    h1 = ax1.plot(xtime,ch4_obs_20d_avg[i],linestyle='None',marker='o',markersize=2.5,color='orange',\n",
    "                  markerfacecolor='None',label='Obs')\n",
    "    h2 = ax1.plot(xtime2,ch4_mod_20d_avg[i],color='k', label='ISAM', linewidth=2.2)\n",
    "    #h3 = ax1.plot(xtime2,ch4_prod_20d_avg[i],color='r', label='ISAM', linewidth=2.2)\n",
    "    #h4 = ax1.plot(xtime2,ch4_oxid_20d_avg[i],color='y', label='ISAM', linewidth=2.2)\n",
    "    h5 = ax1.plot(xtime2,ch4_ebul_20d_avg[i],color='b', label='ISAM', linewidth=2.2)\n",
    "    h6 = ax1.plot(xtime2,ch4_aere_20d_avg[i],color='g', label='ISAM', linewidth=2.2)\n",
    "    h7 = ax1.plot(xtime2,ch4_20d_avg[i],color='r', label='ISAM', linewidth=2.2)\n",
    "    h2 = ax1.plot(xtime2,ch4_mod_20d_avg[i],color='k', label='ISAM', linewidth=2.2)\n",
    "    if (i == 7):\n",
    "        h8 = ax1.plot(xtime2,usstj_mod_20d_avg, color='gray', label='ISAM', linewidth=2.2)\n",
    "    \n",
    "    ax1.grid(color='gray', which='major', axis='both', alpha=0.3)\n",
    "    # ax1.set_ylabel('CH4 flux (gCH4 m-2)', color='k')\n",
    "    # yticks = (0, 20, 40, 60, 80, 100, 120, 140)\n",
    "    # ax1.set_yticklabels(yticks, fontsize=32, minor=False)\n",
    "    # Add +/-1 std to observation\n",
    "\n",
    "    ax1.fill_between(xtime, std_lower, std_upper, color='orange', alpha=.25, label='+/- 1 std')\n",
    "    ax1.plot(xtime, std_lower, alpha=.25, color='orange', linewidth=1.2)\n",
    "    ax1.plot(xtime, std_upper, alpha=.25, color='orange', linewidth=1.2)\n",
    "\n",
    "    #ax1.legend(['Observation', 'Modeled Net Emissions (N)', 'Modeled Ebullition (E)', 'Modeled Aerenchyma Transport (A)', 'Modeled Net Diffusion (D)'], handlelength=3, loc='upper right', fontsize=28)\n",
    " \n",
    "    # Water table\n",
    "    #ax2 = ax1.twinx()\n",
    "    ##plt.ylim((0.0, ylims_wt[i]))\n",
    "    #plt.gca().invert_yaxis()\n",
    "    #h3 = ax2.plot(xtime, wt_obs_20d_avg[i], 'r.')\n",
    "    #ax2.set_ylabel('Water table (m)', color='r')\n",
    "    #ax2.tick_params('y', colors='r')\n",
    "    \n",
    "    years = mdates.YearLocator()   # every year\n",
    "    months = mdates.MonthLocator()  # every month\n",
    "    yearsFmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "    # format the ticks\n",
    "    ax1.xaxis.set_major_locator(years)\n",
    "    ax1.xaxis.set_major_formatter(yearsFmt)\n",
    "    ax1.xaxis.set_minor_locator(months)\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 32})\n",
    "    #fig.autofmt_xdate()\n",
    "    #plt.show()\n",
    "    tit = './calibration/'+site[i]+'.png'\n",
    "    plt.savefig(tit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xtime2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================\n",
    "Date tick labels\n",
    "================\n",
    "\n",
    "Show how to make date plots in matplotlib using date tick locators and\n",
    "formatters.  See major_minor_demo1.py for more information on\n",
    "controlling major and minor ticks\n",
    "\n",
    "All matplotlib date plotting is done by converting date instances into\n",
    "days since the 0001-01-01 UTC.  The conversion, tick locating and\n",
    "formatting is done behind the scenes so this is most transparent to\n",
    "you.  The dates module provides several converter functions date2num\n",
    "and num2date\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator()  # every month\n",
    "yearsFmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "# load a numpy record array from yahoo csv data with fields date,\n",
    "# open, close, volume, adj_close from the mpl-data/example directory.\n",
    "# The record array stores python datetime.date as an object array in\n",
    "# the date column\n",
    "datafile = cbook.get_sample_data('goog.npy')\n",
    "try:\n",
    "    # Python3 cannot load python2 .npy files with datetime(object) arrays\n",
    "    # unless the encoding is set to bytes. However this option was\n",
    "    # not added until numpy 1.10 so this example will only work with\n",
    "    # python 2 or with numpy 1.10 and later.\n",
    "    r = np.load(datafile, encoding='bytes').view(np.recarray)\n",
    "except TypeError:\n",
    "    r = np.load(datafile).view(np.recarray)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(r.date, r.adj_close)\n",
    "\n",
    "\n",
    "# format the ticks\n",
    "ax.xaxis.set_major_locator(years)\n",
    "ax.xaxis.set_major_formatter(yearsFmt)\n",
    "ax.xaxis.set_minor_locator(months)\n",
    "\n",
    "datemin = datetime.date(r.date.min().year, 1, 1)\n",
    "datemax = datetime.date(r.date.max().year + 1, 1, 1)\n",
    "ax.set_xlim(datemin, datemax)\n",
    "\n",
    "\n",
    "# format the coords message box\n",
    "def price(x):\n",
    "    return '$%1.2f' % x\n",
    "ax.format_xdata = mdates.DateFormatter('%Y-%m-%d')\n",
    "ax.format_ydata = price\n",
    "ax.grid(True)\n",
    "\n",
    "# rotates and right aligns the x labels, and moves the bottom of the\n",
    "# axes up to make room for them\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(xtime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
